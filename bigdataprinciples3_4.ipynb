{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data\n",
    "# Principles and best practices of scalable real-time data system\n",
    "## **Part 1 Batch Layer**\n",
    "1. What is the name of the innovative distributed key/value store that it was created by Amazon?\n",
    "\n",
    "Dynamo. The open source community responded in the years following with Hadoop, HBase, MongoDB, Cassandra, RabbitMQ, and countless other projects.\n",
    "\n",
    "**1.2.1Scaling with a queue**\n",
    "\n",
    "2. How to resolve a problem of overloaded provisionally?\n",
    "\n",
    "Insert a queue between the web server and the database\n",
    "\n",
    "**1.2.2 Scaling by sharing the database**\n",
    "\n",
    "3. This technique spread the write load across multiple machines.\n",
    "\n",
    "Horizontal partitioning or sharing\n",
    "\n",
    "**1.2.5 What went wrong?**\n",
    "\n",
    "4. If the application becomes more and more complex, what is most likely to happen?\n",
    "\n",
    "The most likely thing that can happen is a human error that breaks the database and the program.\n",
    "\n",
    "**1.2.6 How will Big Data techniques help?**\n",
    "\n",
    "5. How will Big Data techniques help?\n",
    "\n",
    "Help us to balance our database and computer system when we have storage and resource problems with the techniques we can automate and simplify our programs so that it does not become complex.\n",
    "1.3NoSQL is not a panacea.\n",
    "\n",
    "6. When should we not use Hadoop?\n",
    "\n",
    "Do not use Hadoop for anything where you need low-latency result.\n",
    "\n",
    "**1.4First principles**\n",
    "\n",
    "7. What does a data system do?\n",
    "\n",
    "A data system answers questions based on information that was acquired in the past up to the present.\n",
    "\n",
    "8. What does Lambda architecture provide with this expression?\n",
    "\n",
    "The Lambda Architecture provides a general-purpose approach to implementing\n",
    "an arbitrary function on an arbitrary dataset and having the function return its results\n",
    "with low latency.\n",
    "\n",
    "**1.5.7 Minimal maintenance**\n",
    "\n",
    "9. What are the desired properties of the Big Data?\n",
    "\n",
    "Robustness and fault tolerance, low latency reads and updates, scalability, generalization, extensibility, ad hoc queries, minimal maintenance, and debuggability. \n",
    "\n",
    "10. Why should we do at least a minimum of maintenance on our system?\n",
    "\n",
    "Maintenance is the work required to keep a system running smoothly. This includes anticipating when to add machines to scale, keeping processes up and running, and debugging anything that goes wrong in production. An important part of minimizing maintenance is choosing components that have as little implementation complexity as possible.\n",
    "\n",
    "**1.6.1 Operational complexity**\n",
    "\n",
    "11. What operational complexity should we focus on in the Big Data?\n",
    "\n",
    "we will focus on one: the need for read/write databases to perform online compaction, and what you have to do operationally to keep things running smoothly.\n",
    "\n",
    "**1.6.2 Extreme complexity of achieving eventual consistency**\n",
    "\n",
    "12. What is consistency in terms of database and complexity?\n",
    "\n",
    "Consistency in database systems refers to the requirement that any given database transaction must change affected data only in allowed ways. Also, it turns out that achieving high availability competes directly with another important property called consistency.\n",
    "\n",
    "**1.7 Lambda Architecture**\n",
    "\n",
    "13. What is Lambda Architecture? \n",
    "\n",
    "The main idea of the Lambda Architecture is to build Big Data systems as a series of Layers (speed layer, serving layer, batch layer). Each layer satisfies a subset of the properties and builds upon the functionality provided by the layers beneath it.\n",
    "\n",
    "**1.7.1 Batch layer**\n",
    "\n",
    "14. What does Batch layer do?\n",
    "\n",
    "The batch layer stores the master copy of the dataset and precomputes batch views on that master dataset.\n",
    "\n",
    "**1.7.2 Serving layer**\n",
    "\n",
    "15. What does Serving layer do?\n",
    "\n",
    "The serving layer is a specialized distributed database that loads in a batch view and makes it possible to do random reads on it.\n",
    "\n",
    "**1.7.4 Speed layer**\n",
    "\n",
    "16. What does Speed layer do?\n",
    "\n",
    "The speed layer compensates for high latency of updates to serving layer, incremental algorithms quickly and with batch layer eventually overrides speed layer.\n",
    "\n",
    "### Important!\n",
    "\n",
    "The Lambda Architecture in full is summarized by these three equations:\n",
    "batch view = function(all data)\n",
    "realtime view = function(realtime view, new data)\n",
    "query = function(batch view, realtime view)\n",
    " \n",
    "## **Part 2 Data model for Big Data**\n",
    "\n",
    "**2.1 The properties of data**\n",
    "\n",
    "1. What are the shapes of the data?\n",
    "\n",
    "Our data must have information, it is advisable to know this for our Big Data system. It must have something unique that can be manipulated and used in systems. That can be seen from other databases for collection and that can be queried.\n",
    "\n",
    "2. Why do companies use data standardization?\n",
    "\n",
    "Companies use data normalization to correct duplicates in the database, prevent unwanted storage, reduce database review time and complexity, and facilitate interpretation.\n",
    "\n",
    "**2.1.1 Data is raw**\n",
    "\n",
    "3. When to store unstructured data?\n",
    "\n",
    "Due to its structure we cannot use relational architecture, for which Big Data tools work. But we can use it to extract information and make changes to our algorithm.\n",
    "\n",
    "**2.1.2 Data is immutable**\n",
    "\n",
    "4. What do we get from immutability?\n",
    "\n",
    "We obtain advantages over our mistakes, the fact that the human being makes mistakes does not make lose much value in our database and with the immutability, no data can be lost. And finally, we have the simplicity in the data to add and update relevant data.\n",
    "\n",
    "**2.1.3 Data is eternally true**\n",
    "\n",
    "5. Recycle data?\n",
    "\n",
    "With the garbage collector you can manage the memory automatically, as its function is to remove objects that are no longer in use. And with the regulation you can save information with specific conditions.\n",
    "\n",
    "\n",
    "**2.2 The fact-based model for representing data**\n",
    "\n",
    "6. What is Fact Based Modeling?\n",
    "\n",
    "The main purpose of fact based modeling is to capture as much of the semantics as possible, to validate intermediate and final results with the subject matter expert in his preferred language, preferably using concrete illustrations and to remain independent of the representation for a specific implementation.\n",
    "\n",
    "7. Duplicates are bad?\n",
    "\n",
    "Duplicates can be useful in the big data because when a maximum of users and storage arrive and if the provider makes a mistake in the handling of data it can erase information, then having duplicates we have the possibility of having reserve containers where we possibly have what is needed.\n",
    "\n",
    "**2.3 Graph schemas**\n",
    "\n",
    "8. What a graphic scheme?\n",
    "\n",
    "It is a visual representation of structured, relational data where each type of information present in the database is shown, these have nodes and edges which are related.\n",
    "\n",
    "## **Part 3 Data model for Big Data: Illustration**\n",
    "\n",
    "**3.1 Why a serialization framework?**\n",
    "\n",
    "1. Which errors in the data take the longest to debug?\n",
    "\n",
    "Data corruption errors.\n",
    "\n",
    "2. What are Serialization frameworks?\n",
    "\n",
    "Tey generate code for whatever languages you wish to use for reading, writing, and validating objects that match your schema.\n",
    "\n",
    "**3.2 Apache Thrift**\n",
    "\n",
    "3. What makes the tool Protocol Buffers?\n",
    "\n",
    "It's a method of serializing structured data. It is useful in developing programs to communicate with each other over a wire or for storing data. The method involves an interface description language that describes the structure of some data and a program that generates source code from that description for generating or parsing a stream of bytes that represents the structured data.\n",
    "\n",
    "**3.3 Limitations of serialization frameworks**\n",
    "\n",
    "4. How does The schema language for Apache Thrift benefit us?\n",
    "\n",
    "It helps us to keep restrictions on the data when we input it into the database, to lower the error rate it does not provide functions in which we divide the work for greater efficiency.\n",
    "\n",
    "5. What is the importance of working with a programming language when yuo read/write data?\n",
    "\n",
    "The importance is the decisions you make when working with data, if you use more than one language to read/write data, you need to keep the same logic which can be easy for you, but for what you want to read the code can be complicated. The recommendation is to work with a language that carries the same logic at all times, and not be confusing to other people.\n",
    "\n",
    "## **Part 4 Data Storage on the batch layer**\n",
    "\n",
    "**4.2.1 Using a key/value store for the master dataset**\n",
    "\n",
    "1. What is the key/value storage intended for?\n",
    "\n",
    "Key/value stores are meant to be used as mutable stores, which is a problem if enforcing immutability is so crucial for the master dataset. \n",
    "\n",
    "2. What is teh biggest problem from a key/value store?\n",
    "\n",
    "The biggest problem, though, is that a key/value store has a lot of things you don’t need: random reads, random writes, and all the machinery behind making thosework.\n",
    "\n",
    "**4.2.2 Distributed filesystems**\n",
    "\n",
    "3. What is *distributed filesystem*?\n",
    "\n",
    "Distributed file system (DFS) is a method of storing and accessing files based in a client/server architecture. In a distributed file system, one or more central servers store files that can be accessed, with proper authorization rights, by any number of remote clients in the network.\n",
    "\n",
    "**4.4 Storing a master dataset with a distributed filesystem**\n",
    "\n",
    "4. What are some problems with the empirical data?\n",
    "\n",
    "Gathering empirical data requires modification to an operating system to monitor these parameters. This process itself may impact on the system performance in a small way.\n",
    "\n",
    "When interpreting the data, consideration must be given to the environment in which it was gathered. A study of a file system used in an academic environment may not be sufficiently general for other kinds of environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
